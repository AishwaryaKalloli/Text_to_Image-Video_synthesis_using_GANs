{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5IlgEnKCSx8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **DCGAN implementation of MNIST dataset**\n",
        "\n",
        "Software Requirements:\n",
        "python 3\n",
        "\n",
        "library requirements \n",
        "1.   Torch\n",
        "2.   Torchvision\n",
        "3.   Matplotlib\n",
        "4.   tensorboardX\n",
        "5.    numpy\n",
        "6.   Pillow\n",
        "\n",
        "\n",
        "Running Instructions:\n",
        "1. Install all libraries\n",
        "2. Run the Code cell below \n",
        "\n",
        "DCGAN architecture Details\n",
        "\n",
        "![DCGAN architecture details](https://raw.githubusercontent.com/znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN/master/pytorch_DCGAN.png)\n",
        "\n",
        "\n",
        "Generated images after a few epochs\n",
        "\n",
        "![alt text](https://i.imgur.com/Vp1w3KS.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "LGt4QJHUWkoT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CODE FROM HERE\n"
      ]
    },
    {
      "metadata": {
        "id": "XbUQf8U3O8z7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "from IPython import display\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "# utility file to show image plots , save model, and log tensorboard Data\n",
        "class Logger:\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        var_class = torch.autograd.Variable\n",
        "        if type(d_error) == var_class:\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if type(g_error) == var_class:\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "\n",
        "        if format == 'NHWC':\n",
        "            images = images.transpose(1, 3)\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "\n",
        "        var_class = torch.autograd.Variable\n",
        "        if type(d_error) == var_class:\n",
        "            d_error = d_error.data.cpu().numpy()[0]\n",
        "        if type(g_error) == var_class:\n",
        "            g_error = g_error.data.cpu().numpy()[0]\n",
        "        if type(d_pred_real) == var_class:\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if type(d_pred_fake) == var_class:\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "\n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch, num_epochs, n_batch, num_batches)\n",
        "        )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "                \n",
        "#data generator function to create MNIST data\n",
        "def data_generator():\n",
        "    compose = transforms.Compose([\n",
        "        transforms.Resize(64),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((.5,.5,.5),(.5,.5,.5))\n",
        "    ])\n",
        "    out_dir='{}/dataset'.format('MNIST')\n",
        "    return datasets.MNIST(out_dir,True,compose,download=True)\n",
        "\n",
        "data = data_generator()\n",
        "batch_size = 100\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "num_batches = len(data_loader)\n",
        "\n",
        "\n",
        "#discriminator net \n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1,128,4,2,1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256,4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256,512, 4, 2, 1,bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024*4*4, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        # Flatten and apply sigmoid\n",
        "        x = x.view(-1, 1024*4*4)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "#generator NET\n",
        "class generatorNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(generatorNet, self).__init__()\n",
        "        self.linear = torch.nn.Linear(100, 1024 * 4 * 4)\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1024,512, 4, 2, 1, bias=False ),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128,4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False)\n",
        "        )\n",
        "        self.out = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Project and reshape\n",
        "        x = self.linear(x)\n",
        "        x = x.view(x.shape[0], 1024, 4, 4)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.deconv4(x)\n",
        "        # Apply Tanh\n",
        "        return self.out(x)\n",
        "\n",
        "\n",
        "def noise(size):\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    if torch.cuda.is_available(): return n.cuda()\n",
        "    return n\n",
        "\n",
        "\n",
        "def init_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(0.00, 0.02)\n",
        "\n",
        "generator = generatorNet()\n",
        "discriminator = DiscriminatorNet()\n",
        "\n",
        "generator.apply(init_weights)\n",
        "discriminator.apply(init_weights)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "\n",
        "d_optimizer = Adam(discriminator.parameters(),lr=0.0002, betas=(0.5,0.999))\n",
        "g_optimizer = Adam(generator.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "def real_data_target(size):\n",
        "    if torch.cuda.is_available():\n",
        "        return Variable(torch.ones(size,1)).cuda()\n",
        "    return Variable(torch.ones(size,1))\n",
        "\n",
        "def fake_data_target(size):\n",
        "    if torch.cuda.is_available():\n",
        "        return Variable(torch.zeros(size,1)).cuda()\n",
        "    return Variable(torch.zeros(size,1))\n",
        "\n",
        "#training function for the discriminator\n",
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    optimizer.zero_grad()\n",
        "    prediction_real = discriminator(real_data)\n",
        "    error_real = loss(prediction_real,real_data_target(real_data.size(0)))\n",
        "    error_real.backward()\n",
        "\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    error_fake = loss(prediction_fake,fake_data_target(real_data.size(0)))\n",
        "    error_fake.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    return error_real+error_fake,prediction_real,prediction_fake\n",
        "#training function for the genera\n",
        "def train_generator(optimizer,fake_data):\n",
        "    optimizer.step()\n",
        "    prediction = discriminator(fake_data)\n",
        "    error = loss(prediction,real_data_target(prediction.size(0)))\n",
        "    error.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    return error\n",
        "\n",
        "\n",
        "logger = Logger(model_name='DCGAN', data_name='MNIST')\n",
        "\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch, _) in enumerate(data_loader):\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(real_batch)\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
        "                                                                real_data, fake_data)\n",
        "\n",
        "        # 2. Train Generator\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(real_batch.size(0)))\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "        # Log error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress\n",
        "        if (n_batch) % 10 == 0:\n",
        "            display.clear_output(True)\n",
        "            # Display Images\n",
        "            test_images = generator(test_noise).data.cpu()\n",
        "            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )\n",
        "        # Model Checkpoints\n",
        "        logger.save_models(generator, discriminator, epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}